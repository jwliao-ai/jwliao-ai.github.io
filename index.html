<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0041)https://people.eecs.berkeley.edu/~barron/ -->
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
      color: #07889b;
      /*#1772d0;*/
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #e37222;
      /*#f7b733;*/
      /*f09228;*/
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p {
      font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif;
      /*'Lato', Verdana, Helvetica, sans-serif;*/
      font-size: 15px;
      /*14*/
    }

    a {
      font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif;
      /*'Lato', Verdana, Helvetica, sans-serif;*/
    }

    strong {
      font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif;
      /*'Lato', Verdana, Helvetica, sans-serif;*/
      font-size: 15px;
      /*14*/
    }

    heading {
      font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif;
      /*'Lato', Verdana, Helvetica, sans-serif;*/
      font-size: 22px;
      color: #e37222;
      /*#fc4a1a;*/
    }

    heading2 {
      font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif;
      /*'Lato', Verdana, Helvetica, sans-serif;*/
      font-size: 18px;
    }

    papertitle {
      font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif;
      /*'Lato', Verdana, Helvetica, sans-serif;*/
      font-size: 15px;
      /*14*/
      font-weight: 700;
    }

    name {
      font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif;
      /*'Lato', Verdana, Helvetica, sans-serif;*/
      font-size: 42px;
    }

    li:not(:last-child) {
      margin-bottom: 5px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="https://people.eecs.berkeley.edu/~barron/seal_icon.png">
  <title>Junwei Liao</title>

  <link href="./files/css" rel="stylesheet" type="text/css">
  <style id="dark-reader-style" type="text/css">
    @media screen {

      /* Leading rule */
      /*html {
  -webkit-filter: brightness(100%) contrast(100%) grayscale(20%) sepia(10%) !important;
}*/

      /* Text contrast */
      html {
        text-shadow: 0 0 0 !important;
      }

      /* Full screen */
      *:-webkit-full-screen,
      *:-webkit-full-screen * {
        -webkit-filter: none !important;
      }

      /* Page background */
      html {
        background: rgb(255, 255, 255) !important;
      }

    }
  </style>

  <script type="text/javascript">
    function visibility_on(id) {
      var e = document.getElementById(id + "_text");
      if (e.style.display == 'none')
        e.style.display = 'block';
      var e = document.getElementById(id + "_img");
      if (e.style.display == 'none')
        e.style.display = 'block';
    }
    function visibility_off(id) {
      var e = document.getElementById(id + "_text");
      if (e.style.display == 'block')
        e.style.display = 'none';
      var e = document.getElementById(id + "_img");
      if (e.style.display == 'block')
        e.style.display = 'none';
    }
    function toggle_visibility(id) {
      var e = document.getElementById(id + "_text");
      if (e.style.display == 'inline')
        e.style.display = 'block';
      else
        e.style.display = 'inline';
      var e = document.getElementById(id + "_img");
      if (e.style.display == 'inline')
        e.style.display = 'block';
      else
        e.style.display = 'inline';
    }
    function toggle_vis(id) {
      var e = document.getElementById(id);
      if (e.style.display == 'none')
        e.style.display = 'inline';
      else
        e.style.display = 'none';
    }
  </script>

</head>
</div>
<table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
  <tbody>
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
            <tr>
              <td width="67%" valign="middle">
                <p align="center">
                  <name>Junwei (Jaden) Liao</name><br>
                  jwliao dot ai at gmail dot com
                </p>
                <p>
                  I am a senior undergrad majoring in Artificial Intelligence at
                  <a href="http://en.xjtu.edu.cn/">Xi'an Jiaotong University</a>
                  and was once a visiting student at
                  <a href="https://www.berkeley.edu/" target="_blank">University of California, Berkeley</a>
                  2023 Fall.
                </p>
                </p>
                <p>
                  <i>I am interested in Reinforcement Learning, Large Decision Models,
                    specifically LLM-based Agents and unleashing the full potential of Agents
                    through RL and other advanced techniques.</i>
                </p>

                <p align="center">
                  <!-- <a href="http://ai.stanford.edu/~cbfinn/bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="mailto:jwliao.ai@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://github.com/jwliao-ai" target="_blank"> GitHub </a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/jwliao" target="_blank"> LinkedIn </a>
                </p>
              </td>
              <td width="33%">
                <a href="files/JunweiLiao.jpg"><img width="280" alt="profile photo" src="files/JunweiLiao.jpg"></a>
              </td>
            </tr>
          </tbody>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>

            <tr>
              <td>
                <heading>Education</heading>
                <ul>
                  <li>
                    <b>Sep. 2021 ~ Present</b>: B.S. in Artificial Intelligence at
                    <a href="http://en.xjtu.edu.cn/">Xi'an Jiaotong University</a>.
                  </li>
                  <li>
                    <b>Aug. 2023 ~ Dec. 2023</b>: Visiting Student at
                    <a href="https://www.berkeley.edu/" target="_blank">University of California, Berkeley</a>.
                  </li>
                </ul>
              </td>
            </tr>

            <tr>
              <td>
                <heading>Research Experience</heading>
                <ul>
                  <li><b>May. 2024 ~ Present</b>: RA at
                    <a href="http://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a>,
                    advised by
                    <a href="https://wnzhang.net/" target="_blank">Weinan Zhang</a>.
                  </li>
                  <p>Focus on Deep Reinforcement Learning, Large Decision Models and Agent Technology.</p>
                  <li><b>Sep. 2023 ~ Mar. 2024</b>: RA at
                    <a href="https://www.tsinghua.edu.cn/" target="_blank">Tsinghua University</a>,
                    advised by
                    <a href="https://juren1987.github.io/" target="_blank">Ju Ren</a>.
                  </li>
                  <p>Focus on Deep Reinforcement Learning and RLHF/RLAIF.</p>
                </ul>
              </td>
            </tr>

            <!-- <tr><td>
        <heading>News</heading>
        <p>See our <a href="https://irislab.stanford.edu/">lab website</a> for up-to-date news.</p>
        <ul>
          <li>I am honored and thrilled to have received the <a href="https://awards.acm.org/about/2018-doctoral-dissertation">ACM 2018 Doctoral Dissertation Award</a> for my thesis, <a href="_files/dissertation.pdf">Learning to Learn with Gradients</a>.</li>
          <li> <a href="javascript:toggle_vis('news')">show more</a> </li>
          <div id="news" style="display:none"> 
            <li>I co-organized a workshop at NIPS 2016 on <a href="https://sites.google.com/site/nips16interaction/">Deep Learning for Action and Interaction</a> (<a href="https://www.youtube.com/watch?v=vTgwWobuoFw&list=PL_iWQOsE6TfVCLmikLdaQOBntJuCZLwQY&index=1">videos here</a>). </li>
          </div>
        </ul>
      </td></tr> -->

            <!--
        <tr><td>
            <heading>Blog Posts</heading>
            <ul>
                <li> <a href="https://ai.stanford.edu/blog/prototransformer/">Meta-Learning Student Feedback to 16,000 Solutions</a>: our work on studying meta-learning for education and how we can scale student feedback.</li>
              <li> <a href="javascript:toggle_vis('blogs')">show more</a> </li>
              <div id="blogs" style="display:none"> 
              <li><a href="https://research.googleblog.com/2016/10/how-robots-can-acquire-new-skills-from.html">How Robots Can Acquire New Skills from Their Shared Experience</a>:
              features some work done by me and my colleagues at Google Brain, X, and DeepMind on learning across multiple robots. It was nicely summarized
              by the MIT Technology Review <a href="https://www.technologyreview.com/s/602529/google-builds-a-robotic-hive-mind-kindergarten/">here</a>. </li>
             </div>
            </ul>
        </td></tr>
        -->

            <!-- <tr><td>
             <heading>Recent Talks</heading><br><br>

             <b>Robotics Focused Talk (November 2022)</b>
             <iframe width="780" height="439" src="https://www.youtube.com/embed/m8pQeXe7J0w" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
             <br><br>

             <b>Machine Learning Focused Talk (June 2022)</b>
             <iframe width="780" height="439" src="https://www.youtube.com/embed/gtDo9njJKb8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </td></tr> -->

            <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <heading>Teaching</heading>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tbody><tr>
        <td width="75%" valign="center">
        <p>
          <a href="https://stanford-cs221.github.io/spring2021/"><papertitle>Stanford CS221: Artificial Intelligence: Principles and Techniques</papertitle></a> - Spring 2020, Spring 2021 <br>
        </p>
        </td>
      </tr>
      </tbody></table> -->


            <!-- <tr><td>
            <heading>Tutorials and Lectures</heading>
            <ul>
              <li> In August 2017, I gave guest lectures on model-based reinforcement learning and inverse reinforcement learning at the <a href="https://www.deepbootcamp.io/">Deep RL Bootcamp</a> (slides <a href="_files/mbrl_bootcamp.pdf">here</a> and <a href="_files/bootcamp_inverserl.pdf">here</a>, videos <a href="https://youtu.be/iC2a7M9voYU">here</a> and <a href="https://youtu.be/d9DlQSJQAoI">here</a>). </li>
            </ul>
        </td></tr> -->

            <!-- <tr><td>
            <heading>Invited Talks</heading>
            <ul>
                <li>I gave a talk on meta-learning (<a href="_files/samsung_ai_forum.pdf">slides here</a>, <a href="https://youtu.be/AhvFggX2xow?t=3379">video here</a>) at the Samsung AI Forum in 2020.</li>
                <li> <a href="javascript:toggle_vis('talks')">show more</a> </li>
              <div id="talks" style="display:none"> 
                <li>At RSS 2019, I gave invited talks in the workshops on Simulation to Real World Transfer (<a href="_files/rss19_sim2real.pdf">slides here</a>), the workshop on Task-Informed Grasping (<a href="_files/rss19_tig.pdf">slides here</a>), and the workshop on Women in Robotics (<a href="_files/rss19_women.pdf">slides here</a>) </li>
              </div>
            </ul>
        </td></tr> -->

        <td width="100%" valign="middle">
          <heading>Publications</heading> <br><br>

          <div onmouseover="document.getElementById('agenticir').style.display = 'block';"
            onmouseout="document.getElementById('agenticir').style.display='none';">
            <a href="https://arxiv.org/pdf/2410.09713" target="_blank">
              <papertitle>Agentic Information Retrieval</papertitle>
            </a><br>
            <a href="https://wnzhang.net/" target="_blank">Weinan Zhang</a>,
            <i>Junwei Liao</i>,
            Ning Li,
            Kounianhua Du
            <br>
            <a href="https://arxiv.org/abs/2410.09713" target="_blank">arXiv</a> / <a href="https://arxiv.org/html/2410.09713"
              target="_blank">html</a>
            <br>
            <div id="agenticir" style="display:none">
              In this position paper, we introduce Agentic Information Retrieval (Agentic IR), a novel IR paradigm shaped by the
              capabilities of LLM agents.
            </div>
          </div><br>

          <div onmouseover="document.getElementById('hammer').style.display = 'block';"
            onmouseout="document.getElementById('hammer').style.display='none';">
            <a href="http://arxiv.org/pdf/2410.04587" target="_blank">
              <papertitle>Hammer: Robust Function-Calling for On-Device Language Models via Function Masking</papertitle>
            </a><br>
            Qiqiang Lin*,
            Muning Wen*,
            Qiuying Peng*,
            Guanyu Nie,
            <i>Junwei Liao</i>,
            Jun Wang,
            Xiaoyun Mo,
            Jiamu Zhou,
            Cheng Cheng,
            Yin Zhao,
            Jun Wang,
            <a href="https://wnzhang.net/" target="_blank">Weinan Zhang</a>
            <br>
            <a href="https://arxiv.org/abs/2410.04587" target="_blank">arXiv</a> / <a href="https://github.com/MadeAgents/Hammer"
              target="_blank">code</a> / <a href="https://arxiv.org/html/2410.04587" target="_blank">html</a> / <a
              href="https://huggingface.co/MadeAgents" target="_blank">dataset and
              models</a>
          </div>
          <div id="hammer" style="display:none">
            In this paper, we introduce Hammer, a novel family of foundation
            models specifically engineered for on-device function calling. Hammer employs
            an augmented dataset that enhances models' sensitivity to irrelevant functions and
            incorporates function masking techniques to minimize misleading.
          </div><br>
        
          <div onmouseover="document.getElementById('etpo').style.display = 'block';"
            onmouseout="document.getElementById('etpo').style.display='none';">
            <a href="https://arxiv.org/pdf/2402.06700v4" target="_blank">
              <papertitle>Entropy-Regularized Token-Level Policy Optimization for Language Agent Reinforcement</papertitle>
            </a><br>
            Muning Wen*,
            <i>Junwei Liao</i>*,
            <a href="https://www.cdeng.net/" target="_blank">Cheng Deng</a>,
            <a href="http://www0.cs.ucl.ac.uk/staff/Jun.Wang/" target="_blank">Jun Wang</a>,
            <a href="https://wnzhang.net/" target="_blank">Weinan Zhang</a>,
            <a href="https://yingwen.io/" target="_blank">Ying Wen</a>
            <br>
            <a href="https://arxiv.org/abs/2402.06700" target="_blank">arXiv</a> /
            <a href="https://github.com/morning9393/ETPO" target="_blank">code</a> / <a href="https://arxiv.org/html/2402.06700v4"
              target="_blank">html</a>
            <br>
            <div id="etpo" style="display:none">
              In this paper, we introduce Entropy Regularized Token-level Policy Optimization
              (ETPO), an entropy-augmented RL method tailored for optimizing LLMs at the token level.
            </div>
          </div><br>
        </td>

          <!-- <td width="100%" valign="middle">
            <heading>Selected Publications (<a href="https://irislab.stanford.edu/publications.html">See all</a>)</heading> <br><br>

            <div onmouseover="document.getElementById('tag').style.display = 'block';"
                onmouseout="document.getElementById('tag').style.display='none';">
              <a href="https://arxiv.org/pdf/2109.04617">
                <papertitle>Efficiently Identifying Task Groupings for Multi-Task Learning</papertitle></a><br>
            <a href="https://www.linkedin.com/in/christopher-fifty/">Christopher Fifty</a>,
              <a href="https://scholar.google.com/citations?user=F6omR3gAAAAJ&hl=en">Ehsan Amid</a>, 
              <a href="http://www-personal.umich.edu/~zhezhao/">Zhe Zhao</a>,
              <a href="https://cs.stanford.edu/~tianheyu/">Tianhe Yu</a>,
              <a href="https://scholar.google.com/citations?user=Mv71-IcAAAAJ/">Rohan Anil</a>,
              <i>Chelsea Finn</i><br>
              <em>Neural Information Processing Systems (NeurIPS)</em>, 2021 <font color="#e37222"><strong>(Spotlight)</strong></font> <br>
              <a href="https://arxiv.org/abs/2109.04617">arXiv</a>  / <a href="https://github.com/google-research/google-research/tree/master/tag">code</a>
            </div>
            <div id="tag" style="display:none">  
              </div><br>

            <div onmouseover="document.getElementById('e2e').style.display = 'block';"
                onmouseout="document.getElementById('e2e').style.display='none';">
              <a href="http://www.jmlr.org/papers/volume17/15-522/15-522.pdf">
                <papertitle>End-to-End Training of Deep Visuomotor Policies</papertitle></a><br>
              <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine*</a>,
              <i>Chelsea Finn</i>*, <a href="https://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>,
              <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a><br>
              <strong style="color:#e37222">CCC Blue Sky Ideas <a href="http://www.cccblog.org/2015/08/03/blue-sky-ideas-aaai-rss-special-workshop-on-the-50th-anniversary-of-shakey/">Award</a></strong><br>
              <em>Journal of Machine Learning Research (JMLR)</em>, 2016 <br>
                <a href="https://arxiv.org/abs/1504.00702">arXiv</a> /
                <a href="https://sites.google.com/site/visuomotorpolicy/">video</a> /
                <a href="http://rll.berkeley.edu/deeplearningrobotics">project page</a> /
                <a href="http://rll.berkeley.edu/gps">code</a>
              <br>
              <div id="e2e" style="display:none">
              We demonstrate a deep neural network trained end-to-end, from perception to controls, for robotic manipulation tasks.
              </div>
            </div><br>
          </td> -->

          </tbody>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
            <tr>
              <td>
                <br>
                <p align="right">
                  <font size="2">
                    Last Updated: Oct. 14, 2024
                  </font>
                </p>
                <p align="right">
                  <font size="2">
                    <a href="https://people.eecs.berkeley.edu/~barron/">This guy makes a nice webpage.</a>
                  </font>
                </p>
              </td>
            </tr>
          </tbody>
        </table>

        <script>
          (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
              (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date(); a = s.createElement(o),
              m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
          })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

          ga('create', 'UA-59618557-1', 'auto');
          ga('send', 'pageview');

        </script>

      </td>
    </tr>
  </tbody>
</table>


</body>

</html>